{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8fIrvqaK4vwE"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://docs.pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9naV47w94vwF"
      },
      "source": [
        "[Learn the Basics](intro.html) \\|\\|\n",
        "[Quickstart](quickstart_tutorial.html) \\|\\|\n",
        "[Tensors](tensorqs_tutorial.html) \\|\\| [Datasets &\n",
        "DataLoaders](data_tutorial.html) \\|\\| **Transforms** \\|\\| [Build\n",
        "Model](buildmodel_tutorial.html) \\|\\|\n",
        "[Autograd](autogradqs_tutorial.html) \\|\\|\n",
        "[Optimization](optimization_tutorial.html) \\|\\| [Save & Load\n",
        "Model](saveloadrun_tutorial.html)\n",
        "\n",
        "Transforms\n",
        "==========\n",
        "\n",
        "Data does not always come in its final processed form that is required\n",
        "for training machine learning algorithms. We use **transforms** to\n",
        "perform some manipulation of the data and make it suitable for training.\n",
        "\n",
        "All TorchVision datasets have two parameters -`transform` to modify the\n",
        "features and `target_transform` to modify the labels - that accept\n",
        "callables containing the transformation logic. The\n",
        "[torchvision.transforms](https://pytorch.org/vision/stable/transforms.html)\n",
        "module offers several commonly-used transforms out of the box.\n",
        "\n",
        "The FashionMNIST features are in PIL Image format, and the labels are\n",
        "integers. For training, we need the features as normalized tensors, and\n",
        "the labels as one-hot encoded tensors. To make these transformations, we\n",
        "use `ToTensor` and `Lambda`.\n",
        "\n",
        "\n",
        "为了训练，我们需要把特征变成归一化的张量，把标签变成 one-hot 编码的张量\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1NmTA_hK4vwG",
        "outputId": "bee13dcf-9f45-47f7-c935-b5cb928cd6da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 8.95MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 152kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 2.83MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 8.71MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "#ToTensor()：把 PIL/NumPy 图像转成 torch.FloatTensor，并把像素值缩放到 [0,1]。\n",
        "#Lambda(f)：用你自定义的函数 f 来做变换（这里用于把标签变成 one-hot）。\n",
        "\n",
        "ds = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        "    #Lambda(lambda y: ...)：定义一个函数，输入是标签 y（比如 3）。\n",
        "    #torch.zeros(10, dtype=torch.float)：创建长度为 10 的全 0 向量（10 类：0–9）\n",
        "    #.scatter_(0, torch.tensor(y), value=1)：在第 0 维上，把索引为 y 的位置写成 1（scatter_ 末尾下划线表示“原地修改”）\n",
        "    #scatter_ 的 idx 必须是Tensor 不能是原生int，PyTorch 的这类底层算子通常要求索引也是 Tensor，能在 GPU 上运行，能批量化/向量化，dtype 明确\n",
        "    #_后缀表示原地更改\n",
        "\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "labels = torch.tensor([1,1, ], dtype=torch.long)  # 3 个样本的类别\n",
        "out = torch.zeros(3, 10)                            # 3x10\n",
        "\n",
        "out.scatter_(1, labels.unsqueeze(1), 1)\n",
        "print(out)"
      ],
      "metadata": {
        "id": "o7rf15E78aHf",
        "outputId": "9c564891-0acd-47c9-d366-1511de867653",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6OkaS9M4vwG"
      },
      "source": [
        "ToTensor()\n",
        "==========\n",
        "\n",
        "[ToTensor](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ToTensor)\n",
        "converts a PIL image or NumPy `ndarray` into a `FloatTensor`. and scales\n",
        "the image\\'s pixel intensity values in the range \\[0., 1.\\]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6rsi7z_4vwH"
      },
      "source": [
        "Lambda Transforms\n",
        "=================\n",
        "\n",
        "Lambda transforms apply any user-defined lambda function. Here, we\n",
        "define a function to turn the integer into a one-hot encoded tensor. It\n",
        "first creates a zero tensor of size 10 (the number of labels in our\n",
        "dataset) and calls\n",
        "[scatter\\_](https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_.html)\n",
        "which assigns a `value=1` on the index as given by the label `y`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JIUDNtAy4vwH"
      },
      "outputs": [],
      "source": [
        "target_transform = Lambda(lambda y: torch.zeros(\n",
        "    10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSN_XOzh4vwH"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NosYuiL24vwH"
      },
      "source": [
        "Further Reading\n",
        "===============\n",
        "\n",
        "-   [torchvision.transforms\n",
        "    API](https://pytorch.org/vision/stable/transforms.html)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}